from tabulate import tabulate
from IPython import embed
from cpath_rename import format_name

# Example names from Resnet50
[
  'PyTorch Profiler (0)',
  'Iteration Start: PyTorch Profiler',
  'resnet50_profiler_api.py(24): <module>',
  'torch/profiler/profiler.py(488): step',
  'torch/profiler/profiler.py(504): _transit_action',
  'torch/profiler/profiler.py(101): start_trace',
  'torch/autograd/profiler.py(205): _start_trace',
  '<built-in method kineto_available of PyCapsule object at 0x7f86f5a78720>',
  'torch/profiler/profiler.py(181): _get_distributed_info',
  'torch/distributed/__init__.py(8): is_available',
  '<built-in function hasattr>',
  'torch/distributed/distributed_c10d.py(405): is_initialized',
  'torch/autograd/profiler.py(687): kineto_step',
  '<built-in method _kineto_step of PyCapsule object at 0x7f86f5a786f0>',
  'torch/autograd/profiler.py(436): __init__',
  'typing.py(306): inner',
  'torch/jit/__init__.py(79): annotate',
  'torch/autograd/profiler.py(445): __enter__',
  'torch/_ops.py(137): __call__',
  '<built-in method _record_function_enter_new of PyCapsule object at 0x7f86f27e5d70>',
  'ProfilerStep#4',
  'torch/utils/data/dataloader.py(554): __next__',
  'enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__',
  'torch/utils/data/dataloader.py(1206): _next_data',
  '<built-in function len>',
  'torch/utils/data/dataloader.py(1173): _get_data',
  'torch/utils/data/dataloader.py(1027): _try_get_data',
  'multiprocessing/queues.py(98): get',
  '<built-in function monotonic>',
  '<built-in method acquire of _multiprocessing.SemLock object at 0x7f86f5bc91f0>',
  'multiprocessing/connection.py(258): poll',
  'multiprocessing/connection.py(139): _check_closed',
  'multiprocessing/connection.py(143): _check_readable',
  'multiprocessing/connection.py(428): _poll',
  'multiprocessing/connection.py(922): wait',
  'selectors.py(348): __init__',
  'selectors.py(210): __init__',
  'selectors.py(64): __init__',
  '<built-in function poll>',
  'selectors.py(200): __enter__',
  'selectors.py(352): register',
  'selectors.py(235): register',
  'selectors.py(216): _fileobj_lookup',
  'selectors.py(21): _fileobj_to_fd',
  '<built-in function isinstance>',
  'multiprocessing/connection.py(173): fileno',
  '<string>(1): <lambda>',
  '<built-in method __new__ of type object at 0x9515e0>',
  '<built-in method register of select.poll object at 0x7f86f236e280>',
  'selectors.py(403): select',
  '<built-in function ceil>',
  'selectors.py(276): _key_from_fd',
  'multiprocessing/connection.py(938): <listcomp>',
  'selectors.py(203): __exit__',
  'selectors.py(269): close',
  'multiprocessing/connection.py(213): recv_bytes',
  'multiprocessing/connection.py(418): _recv_bytes',
  'multiprocessing/connection.py(379): _recv',
  '<built-in function read>',
  '<built-in function unpack>',
  '<built-in method write of _io.BytesIO object at 0x7f86f2129fd0>',
  '<built-in method getvalue of _io.BytesIO object at 0x7f86f2129fd0>',
  '<built-in method release of _multiprocessing.SemLock object at 0x7f86f5bb7630>',
  '<built-in method release of _multiprocessing.SemLock object at 0x7f86f5bc91f0>',
  '<built-in function loads>',
  'torch/multiprocessing/reductions.py(296): rebuild_storage_fd',
  'multiprocessing/resource_sharer.py(55): detach',
  'multiprocessing/resource_sharer.py(81): get_connection',
  '<frozen importlib._bootstrap>(404): parent',
  '<built-in method rpartition of str object at 0x7f86f566fd70>',
  'multiprocessing/process.py(37): current_process',
  'multiprocessing/process.py(213): authkey',
  'multiprocessing/connection.py(498): Client',
  'multiprocessing/connection.py(100): address_type',
  'multiprocessing/util.py(116): is_abstract_socket_namespace',
  'multiprocessing/connection.py(88): _validate_family',
  'multiprocessing/connection.py(628): SocketClient',
  '<built-in function getattr>',
  'socket.py(220): __init__',
  'socket.py(236): __enter__',
  'socket.py(504): detach',
  'multiprocessing/connection.py(122): __init__',
  'socket.py(239): __exit__',
  'multiprocessing/connection.py(752): answer_challenge',
  '<built-in method write of _io.BytesIO object at 0x7f86f2129940>',
  '<built-in method write of _io.BytesIO object at 0x7f86f212a840>',
  'hmac.py(167): new',
  'hmac.py(38): __init__',
  'hmac.py(66): _init_hmac',
  '<built-in function hmac_new>',
  'hmac.py(151): digest',
  'hmac.py(139): _current',
  'multiprocessing/connection.py(186): send_bytes',
  'multiprocessing/connection.py(147): _check_writable',
  'multiprocessing/connection.py(395): _send_bytes',
  '<built-in function pack>',
  'multiprocessing/connection.py(370): _send',
  '<built-in function write>',
  '<built-in method getvalue of _io.BytesIO object at 0x7f86f212a840>',
  'multiprocessing/connection.py(737): deliver_challenge',
  '<built-in function urandom>',
  '<built-in function getpid>',
  'multiprocessing/connection.py(207): send',
  'multiprocessing/reduction.py(48): dumps',
  'multiprocessing/reduction.py(38): __init__',
  'multiprocessing/connection.py(264): __enter__',
  'multiprocessing/reduction.py(186): recv_handle',
  'socket.py(539): fromfd',
  '<built-in function dup>',
  'multiprocessing/reduction.py(153): recvfds',
  '<built-in function CMSG_SPACE>',
  'socket.py(498): close',
  'socket.py(494): _real_close',
  'multiprocessing/connection.py(178): close',
  'multiprocessing/connection.py(267): __exit__',
  'multiprocessing/connection.py(365): _close',
  '<built-in function close>',
  'multiprocessing/connection.py(135): __del__',
  'torch/multiprocessing/reductions.py(281): fd_id',
  '<built-in function fstat>',
  'torch/multiprocessing/reductions.py(289): storage_from_cache',
  'torch/multiprocessing/reductions.py(57): get',
  '<built-in method _new_shared_fd of type object at 0x7f8800fff6c0>',
  '[memory]',
  'torch/multiprocessing/reductions.py(28): __init__',
  'torch/multiprocessing/reductions.py(61): __setitem__',
  'torch/multiprocessing/reductions.py(328): rebuild_typed_storage',
  'torch/storage.py(274): __new__',
  '<built-in method __new__ of type object at 0x95bde0>',
  'torch/storage.py(341): __init__',
  'torch/multiprocessing/reductions.py(90): rebuild_tensor',
  'torch/_utils.py(132): _rebuild_tensor',
  'torch/storage.py(419): _untyped',
  '<built-in method tensor of type object at 0x7f8801000f80>',
  'aten::empty',
  'aten::to',
  'aten::detach_',
  'detach_',
  'aten::set_',
  '<built-in method write of _io.BytesIO object at 0x7f86f212a1b0>',
  '<built-in method getvalue of _io.BytesIO object at 0x7f86f212a1b0>',
  'void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)',
  'ncclKernel_Reduce_RING_LL_Sum_float(ncclWorkElem)',
  '<built-in method write of _io.BytesIO object at 0x7f86f212aa20>',
  '<built-in method write of _io.BytesIO object at 0x7f86f2129760>',
  '<built-in method getvalue of _io.BytesIO object at 0x7f86f2129760>',
  '<built-in method write of _io.BytesIO object at 0x7f86f21290d0>',
  '<built-in method getvalue of _io.BytesIO object at 0x7f86f21290d0>',
  'torch/utils/data/dataloader.py(1275): _process_data',
  'torch/utils/data/dataloader.py(1255): _try_put_index',
  'torch/utils/data/dataloader.py(548): _next_index',
  '<built-in function next>',
  'torch/utils/data/sampler.py(237): __iter__',
  'torch/utils/data/sampler.py(128): __iter__',
  'multiprocessing/queues.py(86): put',
  '<built-in method acquire of _multiprocessing.SemLock object at 0x7f86f2353ef0>',
  'threading.py(264): __enter__',
  'threading.py(359): notify',
  'threading.py(279): _is_owned',
  'threading.py(267): __exit__',
  'torch/autograd/profiler.py(449): __exit__',
  '<built-in method _record_function_exit of PyCapsule object at 0x7f86f27e5c50>',
  '<built-in function print>',
  'aten::_to_copy',
  'aten::empty_strided',
  'aten::copy_',
  'cudaMemcpyAsync',
  'void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)',
  'void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float> >, at::detail::Array<char*, 2>)',
  'Memcpy HtoD (Pageable -> Device)',
  'cudaStreamSynchronize',
  'nn.Module: DataParallel',
  '<built-in method _get_tracing_state of PyCapsule object at 0x7f8801e56eb0>',
  'torch/nn/parallel/data_parallel.py(147): forward',
  'DataParallel.forward',
  'torch/nn/modules/module.py(1191): __getattr__',
  'torch/nn/modules/module.py(1597): parameters',
  'torch/nn/modules/module.py(1621): named_parameters',
  'torch/nn/modules/module.py(1584): _named_members',
  'torch/nn/modules/module.py(1751): named_modules',
  'torch/nn/modules/module.py(1642): <lambda>',
  'torch/nn/modules/module.py(1785): named_modules',
  '<built-in method add of set object at 0x7f86f2322b20>',
  'torch/_tensor.py(730): __hash__',
  '<built-in function _has_torch_function_unary>',
  '<built-in function id>',
  '<built-in method add of set object at 0x7f86f2322a40>',
  'torch/nn/modules/module.py(1618): parameters',
  'torch/nn/modules/module.py(1641): named_parameters',
  'torch/nn/modules/module.py(1590): _named_members',
  'torch/nn/modules/module.py(1789): named_modules',
  '<built-in method items of collections.OrderedDict object at 0x7f86f24d4640>',
  'torch/nn/modules/module.py(1647): buffers',
  'torch/nn/modules/module.py(1669): named_buffers',
  'torch/nn/modules/module.py(1690): <lambda>',
  'torch/nn/modules/module.py(1666): buffers',
  'torch/nn/modules/module.py(1689): named_buffers',
  'torch/nn/parallel/data_parallel.py(174): scatter',
  'torch/nn/parallel/scatter_gather.py(42): scatter_kwargs',
  'torch/nn/parallel/scatter_gather.py(11): scatter',
  'torch/nn/parallel/scatter_gather.py(17): scatter_map',
  'torch/nn/parallel/scatter_gather.py(4): is_namedtuple',
  'Scatter',
  'torch/nn/parallel/_functions.py(87): forward',
  'torch/nn/parallel/_functions.py(89): <listcomp>',
  'torch/_utils.py(505): _get_device_index',
  'torch/cuda/__init__.py(76): is_available',
  '<built-in function _cuda_getDeviceCount>',
  'torch/nn/parallel/comm.py(152): scatter',
  'torch/_utils.py(547): _handle_complex',
  'torch/nn/parallel/comm.py(188): <listcomp>',
  '<built-in method _scatter of PyCapsule object at 0x7f8801ea3f90>',
  'aten::chunk',
  'aten::split',
  'aten::narrow',
  'aten::slice',
  'aten::as_strided',
  'cudaStreamWaitEvent',
  'Memcpy DtoH (Device -> Device)',
  'Memcpy HtoD (Device -> Device)',
  'torch/nn/parallel/scatter_gather.py(49): <genexpr>',
  'torch/nn/parallel/data_parallel.py(171): replicate',
  '<built-in function is_grad_enabled>',
  'torch/nn/parallel/replicate.py(78): replicate',
  'torch/nn/parallel/replicate.py(34): _replicatable_module',
  'torch/nn/parallel/replicate.py(22): _is_jit_enabled',
  'torch/jit/_state.py(39): __bool__',
  'torch/nn/parallel/replicate.py(7): _is_script_module',
  'torch/nn/modules/module.py(1695): children',
  'torch/nn/modules/module.py(1704): named_children',
  'torch/nn/modules/module.py(1701): children',
  'torch/nn/modules/module.py(1720): named_children',
  'torch/nn/parallel/replicate.py(86): <listcomp>',
]


tests = [
  {
    'in': 'torch/utils/data/dataloader.py(1173): _get_data',
    'out': '_get_data dataloader.py',
  },
  {
    'in': 'torch/nn/parallel/comm.py(188): <listcomp>',
    'out': 'listcomp comm.py',
  },
  {
    'in': 'typing.py(306): inner',
    'out': 'inner typing.py',
  },
  {
    'in': '<built-in method acquire of _multiprocessing.SemLock object at 0x7f86f5bc91f0>',
    'out': 'acquire SemLock',
  },
  {
    'in': '<built-in method _scatter of PyCapsule object at 0x7f8801ea3f90>',
    'out': '_scatter PyCapsule',
  },
  {
    'in': '<string>(1): <lambda>',
    'out': 'lambda string',
  },
  {
    'in': 'aten::slice',
    'out': 'aten::slice',
  },
  {
    'in': '<built-in function print>',
    'out':  'print',
  },
  # Example GPU kernels
  {
    'in': 'void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)',
    'out': 'vectorized_elementwise_kernel<4, CUDAFunctor_add<float>, Array<char*, 3> >(int, CUDAFunctor_add<float>, Array<char*, 3>)'
  },
  {
    'in': 'void wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)',
    'out': 'wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)'
  },
  {
    'in': 'volta_sgemm_64x64_nt',
    'out': 'volta_sgemm_64x64_nt'
  },
  {
    'in': 'void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)',
    'out': 'vectorized_elementwise_kernel<4, BinaryFunctor<float, float, float, threshold_kernel_impl<float>(TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, Array<char*, 3> >(int, BinaryFunctor<float, float, float, threshold_kernel_impl<float>(TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, Array<char*, 3>)'
  },

]

"""
Example CPU Operation Names:
torch/utils/data/dataloader.py(1173): _get_data
torch/nn/parallel/comm.py(188): <listcomp>
typing.py(306): inner
<string>(1): <lambda>
aten::slice
<built-in method acquire of _multiprocessing.SemLock object a
<built-in method _scatter of PyCapsule object at 0x7f8801ea3f90>
<built-in function print>

Example GPU Kernel Names:
void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)
void wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)
volta_sgemm_64x64_nt
void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)
"""

for test in tests:
  try:
    output = format_name(test['in'])
    assert output == test['out']
  except AssertionError as e:
    msg = f'FAILED\nINPUT     = {test["in"]}\nEXPECTED = {test["out"]}\nACTUAL   = {output}'
    raise AssertionError(msg)


print(tabulate(tests,
          headers={'in':'Operation Name','out':'Hotline Renamed'},
          maxcolwidths=[50, 40],
          tablefmt='orgtbl'))


print('All tests passed âœ…')